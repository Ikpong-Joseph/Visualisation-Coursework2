{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "353793d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: pyspark in c:\\users\\y3x51\\appdata\\roaming\\python\\python38\\site-packages (3.5.5)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\y3x51\\appdata\\roaming\\python\\python38\\site-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "# In a notebook cell, prefix with ! to run shell commands\n",
    "!pip install pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "254eb082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 3.5.5\n"
     ]
    }
   ],
   "source": [
    "# Next cell—start Spark and bring in the SQL/DataFrame API\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import hour, month, when, col, count\n",
    "\n",
    "# Create a SparkSession (the entry point for DataFrame & ML operations)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"UKAccidentAnalysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Optional: show Spark version to confirm it’s running\n",
    "print(\"Spark version:\", spark.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6507826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 1504150\n"
     ]
    }
   ],
   "source": [
    "# Read & Cache the Full CSV\n",
    "\n",
    "# Adjust the path to point at your full dataset\n",
    "path = \"UK_Accident.csv\"\n",
    "\n",
    "# Ingest the file in parallel, inferring schema and reading header row\n",
    "df = spark.read.csv(path, header=True, inferSchema=True)\n",
    "\n",
    "# Cache it in memory for fast repeated access\n",
    "df = df.cache()\n",
    "\n",
    "# Quick count to verify you have ~1,000,000 rows\n",
    "print(\"Total records:\", df.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edb29a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-----------+--------+-------------------+----+-----+\n",
      "|Date      |Time               |Date_parsed|Time_str|Datetime           |Hour|Month|\n",
      "+----------+-------------------+-----------+--------+-------------------+----+-----+\n",
      "|04/01/2005|2025-05-12 17:42:00|2005-01-04 |17:42   |2005-01-04 17:42:00|17  |1    |\n",
      "|05/01/2005|2025-05-12 17:36:00|2005-01-05 |17:36   |2005-01-05 17:36:00|17  |1    |\n",
      "|06/01/2005|2025-05-12 00:15:00|2005-01-06 |00:15   |2005-01-06 00:15:00|0   |1    |\n",
      "|07/01/2005|2025-05-12 10:35:00|2005-01-07 |10:35   |2005-01-07 10:35:00|10  |1    |\n",
      "|10/01/2005|2025-05-12 21:13:00|2005-01-10 |21:13   |2005-01-10 21:13:00|21  |1    |\n",
      "+----------+-------------------+-----------+--------+-------------------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_timestamp, concat_ws, hour, month, when, col\n",
    "\n",
    "'''\n",
    "# 1) Parse Date & Time into a true timestamp using your pattern\n",
    "df = df.withColumn(\n",
    "    \"Datetime\",\n",
    "    to_timestamp(\n",
    "        concat_ws(\" \", col(\"Date\"), col(\"Time\")),   # e.g. \"08/06/2005 14:30\"\n",
    "        \"dd/MM/yyyy HH:mm\"                         # exact format of your data\n",
    "    )\n",
    ")\n",
    "\n",
    "# 2) Extract all the temporal features once you have a valid Datetime\n",
    "df = df.withColumn(\"Hour\", hour(\"Datetime\")) \\\n",
    "       .withColumn(\"Month\", month(\"Datetime\")) \\\n",
    "       .withColumn(\n",
    "           \"IsWeekend\",\n",
    "           when(col(\"Day_of_Week\").isin(1, 7), 1).otherwise(0)\n",
    "       )\n",
    "\n",
    "# 3) (Optional) check that parse worked\n",
    "df.select(\"Date\", \"Time\", \"Datetime\", \"Hour\", \"Month\") \\\n",
    "  .where(col(\"Datetime\").isNull()) \\\n",
    "  .show(5, truncate=False)\n",
    "\n",
    "# 4) Re-run the aggregation to verify\n",
    "df.groupBy(\"Month\", \"Accident_Severity\") \\\n",
    "  .count() \\\n",
    "  .orderBy(\"Month\", \"Accident_Severity\") \\\n",
    "  .show(48)\n",
    "'''\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import to_date, date_format, to_timestamp, concat_ws, hour, month, when, col\n",
    "\n",
    "# 1) Parse Date\n",
    "df = df.withColumn(\"Date_parsed\", to_date(col(\"Date\"), \"dd/MM/yyyy\"))\n",
    "\n",
    "# 2) Turn the Time timestamp into \"HH:mm\" strings\n",
    "df = df.withColumn(\"Time_str\", date_format(col(\"Time\"), \"HH:mm\"))\n",
    "\n",
    "# 3) Build a YYYY-MM-DD HH:mm string and parse it\n",
    "df = df.withColumn(\n",
    "    \"Datetime\",\n",
    "    to_timestamp(\n",
    "        concat_ws(\" \",\n",
    "                  date_format(col(\"Date_parsed\"), \"yyyy-MM-dd\"),\n",
    "                  col(\"Time_str\")),\n",
    "        \"yyyy-MM-dd HH:mm\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# 4) Extract Hour & Month\n",
    "df = df.withColumn(\"Hour\", hour(\"Datetime\")) \\\n",
    "       .withColumn(\"Month\", month(\"Datetime\"))\n",
    "\n",
    "# 5) Weekend flag\n",
    "df = df.withColumn(\n",
    "    \"IsWeekend\",\n",
    "    when(col(\"Day_of_Week\").isin(1, 7), 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# 6) Verify\n",
    "df.select(\"Date\",\"Time\",\"Date_parsed\",\"Time_str\",\"Datetime\",\"Hour\",\"Month\") \\\n",
    "  .show(5,truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0d26dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"Hour\",\"IsWeekend\",\"Speed_limit\",\"Number_of_Vehicles\"],\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"skip\"   # skip any row where an input is null\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=[indexer, assembler, spark_lr])\n",
    "model = pipeline.fit(df)   # now null rows are just ignored\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67533791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+----------+\n",
      "|Accident_Severity|label|prediction|\n",
      "+-----------------+-----+----------+\n",
      "|                2|  1.0|       0.0|\n",
      "|                3|  0.0|       0.0|\n",
      "|                3|  0.0|       0.0|\n",
      "|                3|  0.0|       0.0|\n",
      "|                3|  0.0|       0.0|\n",
      "|                3|  0.0|       0.0|\n",
      "|                3|  0.0|       0.0|\n",
      "|                3|  0.0|       0.0|\n",
      "|                3|  0.0|       0.0|\n",
      "|                3|  0.0|       0.0|\n",
      "+-----------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ML\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression as SparkLogistic\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 4a. Index the target (Severity) to numeric labels\n",
    "indexer = StringIndexer(inputCol=\"Accident_Severity\", outputCol=\"label\")\n",
    "\n",
    "# 4b. Assemble your features into a single vector\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"Hour\", \"IsWeekend\", \"Speed_limit\", \"Number_of_Vehicles\"],\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"skip\"\n",
    ")\n",
    "\n",
    "# 4c. Define a Spark-powered logistic regression\n",
    "spark_lr = SparkLogistic(maxIter=20, regParam=0.1)\n",
    "\n",
    "# 4d. Build & run the pipeline\n",
    "pipeline = Pipeline(stages=[indexer, assembler, spark_lr])\n",
    "model = pipeline.fit(df)  # trains on all 1 M rows in parallel\n",
    "\n",
    "# 4e. Make predictions & inspect a few rows\n",
    "preds = model.transform(df).select(\"Accident_Severity\", \"label\", \"prediction\")\n",
    "preds.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cbd4202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8511\n",
      "F1: 0.7827\n",
      "Weightedprecision: 0.7244\n",
      "Weightedrecall: 0.8511\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# preds is your DataFrame with columns: label, prediction\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "for metric in [\"accuracy\", \"f1\", \"weightedPrecision\", \"weightedRecall\"]:\n",
    "    evaluator.setMetricName(metric)\n",
    "    score = evaluator.evaluate(preds)\n",
    "    print(f\"{metric.capitalize()}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3950bbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-------+\n",
      "|prediction|label|  count|\n",
      "+----------+-----+-------+\n",
      "|       0.0|  0.0|1280109|\n",
      "|       0.0|  1.0| 204484|\n",
      "|       0.0|  2.0|  19440|\n",
      "+----------+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "preds.groupBy(\"prediction\", \"label\")\\\n",
    "     .count()\\\n",
    "     .orderBy(\"prediction\",\"label\")\\\n",
    "     .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e4fe874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5068\n",
      "f1: 0.6048\n",
      "weightedPrecision: 0.7915\n",
      "weightedRecall: 0.5068\n",
      "+----------+-----+------+\n",
      "|prediction|label| count|\n",
      "+----------+-----+------+\n",
      "|       0.0|  0.0|686021|\n",
      "|       0.0|  1.0| 73753|\n",
      "|       0.0|  2.0|  3570|\n",
      "|       1.0|  0.0|267382|\n",
      "|       1.0|  1.0| 65059|\n",
      "|       1.0|  2.0|  4746|\n",
      "|       2.0|  0.0|326706|\n",
      "|       2.0|  1.0| 65672|\n",
      "|       2.0|  2.0| 11124|\n",
      "+----------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model initially wrongly predicted based on majority of minor naccident severity\n",
    "\n",
    "from pyspark.sql.functions import lit, when, col\n",
    "from pyspark.ml.classification import LogisticRegression as SparkLogistic\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# 1) Compute inverse-frequency weights for each original severity\n",
    "counts = df.groupBy(\"Accident_Severity\").count().collect()\n",
    "total = sum(r['count'] for r in counts)\n",
    "weights = {r['Accident_Severity']: total/r['count'] for r in counts}\n",
    "\n",
    "# 2) Look up how StringIndexer mapped severity→label\n",
    "#    (run this after you fit the original indexer)\n",
    "labels = indexer.fit(df).labels  \n",
    "# e.g. labels = ['3','2','1'] in descending frequency\n",
    "\n",
    "# 3) Create a column of weights based on the indexed label\n",
    "df_weighted = df.withColumn(\n",
    "    \"classWeight\",\n",
    "    when(col(\"Accident_Severity\") == int(labels[0]), lit(weights[int(labels[0])]))\n",
    "    .when(col(\"Accident_Severity\") == int(labels[1]), lit(weights[int(labels[1])]))\n",
    "    .otherwise(lit(weights[int(labels[2])]))\n",
    ")\n",
    "\n",
    "# 4) Rebuild the pipeline with weightCol on the LR stage\n",
    "spark_lr_weighted = SparkLogistic(\n",
    "    maxIter=20,\n",
    "    regParam=0.1,\n",
    "    weightCol=\"classWeight\"\n",
    ")\n",
    "pipeline_w = Pipeline(stages=[indexer, assembler, spark_lr_weighted])\n",
    "\n",
    "# 5) Fit & evaluate on the weighted DataFrame\n",
    "model_w = pipeline_w.fit(df_weighted)\n",
    "preds_w  = model_w.transform(df_weighted)\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "for metric in [\"accuracy\",\"f1\",\"weightedPrecision\",\"weightedRecall\"]:\n",
    "    evaluator.setMetricName(metric)\n",
    "    print(f\"{metric}: {evaluator.evaluate(preds_w):.4f}\")\n",
    "\n",
    "# 6) Confusion matrix for weighted model\n",
    "preds_w.groupBy(\"prediction\",\"label\").count().orderBy(\"prediction\",\"label\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a897aab5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
